{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c328c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "# Imports\n",
    "from scipy.signal import resample\n",
    "import pywt\n",
    "import heartpy as hp\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import butter, filtfilt, resample\n",
    "from scipy import signal\n",
    "from data_subplot import data_subplot\n",
    "from scipy.stats import pearsonr\n",
    "from detect_body_movements import detect_patterns\n",
    "from band_pass_filtering import band_pass_filtering\n",
    "from modwt_matlab_fft import modwt\n",
    "from modwt_mra_matlab_fft import modwtmra\n",
    "import math\n",
    "from remove_nonLinear_trend import remove_nonLinear_trend\n",
    "from compute_vitals import vitals\n",
    "dataset_folder = r\"D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\data\\dataset\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc8afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyWavelets in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from PyWavelets) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyWavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec63119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: heartpy in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from heartpy) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from heartpy) (1.14.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from heartpy) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->heartpy) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->heartpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->heartpy) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->heartpy) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->heartpy) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->heartpy) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->heartpy) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->heartpy) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->heartpy) (1.16.0)\n",
      "Requirement already satisfied: pyfftw in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfftw) (1.26.4)\n",
      "Requirement already satisfied: setuptools>=70.1.1 in c:\\users\\hafez\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfftw) (80.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install heartpy\n",
    "!pip install pyfftw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aff64d",
   "metadata": {},
   "source": [
    "## 1. File Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e692a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bcg_with_timestamps(file_path):\n",
    "    \"\"\"Load BCG data and generate timestamps for all samples\"\"\"\n",
    "    try:\n",
    "        # Read CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract metadata from first row\n",
    "        initial_timestamp = df.at[0, 'Timestamp']\n",
    "        fs = df.at[0, 'fs']  # Sampling frequency in Hz\n",
    "        sample_interval = (1/fs) * 1000  # Milliseconds per sample\n",
    "\n",
    "        # Generate timestamps for all samples\n",
    "        timestamps = [initial_timestamp + i*sample_interval\n",
    "                      for i in range(len(df))]\n",
    "\n",
    "        # Add timestamps and clean dataframe\n",
    "        df['Timestamp'] = timestamps\n",
    "        df['Datetime'] = pd.to_datetime(df['Timestamp'], unit='ms')\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "def load_reference_rr_data(file_path):\n",
    "    \"\"\"Robust RR timestamp parser with multiple fallback options\"\"\"\n",
    "    try:\n",
    "        # Read CSV with stricter parsing\n",
    "        df = pd.read_csv(file_path, engine='python')\n",
    "\n",
    "        # Clean column names (strip whitespace)\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Check for required columns\n",
    "        required_cols = ['Timestamp', 'RR Interval in seconds']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"Missing required columns in {file_path}\")\n",
    "            return None\n",
    "\n",
    "        # Pre-clean timestamps\n",
    "        df['Timestamp'] = df['Timestamp'].astype(str).str.strip()\n",
    "\n",
    "        # Try multiple parsing methods\n",
    "        parsed_successfully = False\n",
    "\n",
    "        # Method 1: Direct parsing with expected format\n",
    "        df['Datetime'] = pd.to_datetime(\n",
    "            df['Timestamp'],\n",
    "            format='%d-%m-%y %H:%M',\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "        # Method 2: Try with different delimiters if first fails\n",
    "        if df['Datetime'].isna().all():\n",
    "            df['Datetime'] = pd.to_datetime(\n",
    "                df['Timestamp'].str.replace('-', '/'),\n",
    "                format='%d/%m/%y %H:%M',\n",
    "                errors='coerce'\n",
    "            )\n",
    "\n",
    "        # Method 3: Try parsing as day first without explicit format\n",
    "        if df['Datetime'].isna().all():\n",
    "            df['Datetime'] = pd.to_datetime(\n",
    "                df['Timestamp'],\n",
    "                dayfirst=True,\n",
    "                errors='coerce'\n",
    "            )\n",
    "\n",
    "        # Method 4: Final fallback - string manipulation\n",
    "        if df['Datetime'].isna().all():\n",
    "            try:\n",
    "                # Extract components manually\n",
    "                parts = df['Timestamp'].str.extract(\n",
    "                    r'(\\d{2})-(\\d{2})-(\\d{2}) (\\d{2}):(\\d{2})')\n",
    "                df['Datetime'] = pd.to_datetime(\n",
    "                    '20' + parts[2] + '-' + parts[1] + '-' +\n",
    "                    parts[0] + ' ' + parts[3] + ':' + parts[4],\n",
    "                    format='%Y-%m-%d %H:%M',\n",
    "                    errors='coerce'\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Verify parsing succeeded\n",
    "        if df['Datetime'].isna().all():\n",
    "            print(f\"Failed to parse timestamps in {file_path}\")\n",
    "            print(\"First 5 raw timestamps:\")\n",
    "            print(df['Timestamp'].head())\n",
    "            return None\n",
    "\n",
    "        # Filter out any remaining NaT values\n",
    "        df = df.dropna(subset=['Datetime'])\n",
    "\n",
    "        # Ensure proper column names\n",
    "        df = df.rename(columns={\n",
    "            'RR Interval in seconds': 'RR_Interval',\n",
    "            'Heart Rate': 'HR'\n",
    "        })\n",
    "\n",
    "        \n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_all_bcg_files_with_reference(root_folder):\n",
    "    \"\"\"Load all BCG files that have corresponding reference RR data\"\"\"\n",
    "    bcg_data = {}\n",
    "    file_count = 0\n",
    "\n",
    "    print(\"Loading BCG files with reference RR data...\")\n",
    "\n",
    "    for folder_num in tqdm(range(1, 33), desc=\"Folders\"):\n",
    "        folder_name = f\"{folder_num:02d}\"\n",
    "        bcg_folder = os.path.join(root_folder, folder_name, \"bcg\")\n",
    "        reference_rr_folder = os.path.join(\n",
    "            root_folder, folder_name, \"reference\", \"RR\")\n",
    "\n",
    "        # Skip if folders don't exist\n",
    "        if not os.path.exists(bcg_folder):\n",
    "            print(f\"\\nWarning: BCG folder missing for subject {folder_name}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(reference_rr_folder):\n",
    "            print(\n",
    "                f\"\\nWarning: RR reference folder missing for subject {folder_name}\")\n",
    "            continue\n",
    "\n",
    "        # Process each BCG file\n",
    "        for bcg_file in os.listdir(bcg_folder):\n",
    "            if not bcg_file.lower().endswith('_bcg.csv'):\n",
    "                continue\n",
    "\n",
    "            # Construct corresponding RR filename\n",
    "            rr_file = bcg_file.replace('_BCG.csv', '_RR.csv')\n",
    "            rr_path = os.path.join(reference_rr_folder, rr_file)\n",
    "\n",
    "            if not os.path.exists(rr_path):\n",
    "                print(f\"\\nReference file not found: {rr_file}\")\n",
    "                continue\n",
    "\n",
    "            # Load both BCG and RR data\n",
    "            bcg_path = os.path.join(bcg_folder, bcg_file)\n",
    "\n",
    "            try:\n",
    "                bcg_df = load_bcg_with_timestamps(bcg_path)\n",
    "                rr_df = load_reference_rr_data(rr_path)  # NEW: Load RR data\n",
    "\n",
    "                if bcg_df is not None and rr_df is not None:\n",
    "                    bcg_data[bcg_path] = {\n",
    "                        'bcg_data': bcg_df,\n",
    "                        'rr_data': rr_df,  # NEW: Store RR DataFrame\n",
    "                        'ref_file_path': rr_path\n",
    "                    }\n",
    "                    file_count += 1\n",
    "                    print(f\"\\nMatched: {bcg_file} with {rr_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError loading {bcg_path}: {str(e)}\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nSuccessfully loaded {file_count} BCG files with reference RR data\")\n",
    "    return bcg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e627553",
   "metadata": {},
   "source": [
    "## 2. Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4780938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BCG files with reference RR data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4b4c2341b546d2b5a237922a720b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folders:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: BCG folder missing for subject 01\n",
      "\n",
      "Warning: BCG folder missing for subject 02\n",
      "\n",
      "Warning: BCG folder missing for subject 03\n",
      "\n",
      "Warning: BCG folder missing for subject 04\n",
      "\n",
      "Warning: BCG folder missing for subject 05\n",
      "\n",
      "Warning: BCG folder missing for subject 06\n",
      "\n",
      "Warning: BCG folder missing for subject 07\n",
      "\n",
      "Warning: BCG folder missing for subject 08\n",
      "\n",
      "Warning: BCG folder missing for subject 09\n",
      "\n",
      "Warning: BCG folder missing for subject 10\n",
      "\n",
      "Warning: BCG folder missing for subject 11\n",
      "\n",
      "Warning: BCG folder missing for subject 12\n",
      "\n",
      "Warning: BCG folder missing for subject 13\n",
      "\n",
      "Warning: BCG folder missing for subject 14\n",
      "\n",
      "Warning: BCG folder missing for subject 15\n",
      "\n",
      "Warning: BCG folder missing for subject 16\n",
      "\n",
      "Warning: BCG folder missing for subject 17\n",
      "\n",
      "Warning: BCG folder missing for subject 18\n",
      "\n",
      "Warning: BCG folder missing for subject 19\n",
      "\n",
      "Warning: BCG folder missing for subject 20\n",
      "\n",
      "Warning: BCG folder missing for subject 21\n",
      "\n",
      "Warning: BCG folder missing for subject 22\n",
      "\n",
      "Warning: BCG folder missing for subject 23\n",
      "\n",
      "Warning: BCG folder missing for subject 24\n",
      "\n",
      "Warning: BCG folder missing for subject 25\n",
      "\n",
      "Warning: BCG folder missing for subject 26\n",
      "\n",
      "Warning: BCG folder missing for subject 27\n",
      "\n",
      "Warning: BCG folder missing for subject 28\n",
      "\n",
      "Warning: BCG folder missing for subject 29\n",
      "\n",
      "Warning: BCG folder missing for subject 30\n",
      "\n",
      "Reference file not found: 31_20240115_RR.csv\n",
      "\n",
      "Reference file not found: 31_20240116_RR.csv\n",
      "\n",
      "Reference file not found: 31_20240117_RR.csv\n",
      "\n",
      "Reference file not found: 31_20240118_RR.csv\n",
      "\n",
      "Reference file not found: 31_20240119_RR.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafez\\AppData\\Local\\Temp\\ipykernel_40028\\4205795995.py:67: UserWarning: Parsing dates in %Y/%m/%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Datetime'] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matched: 31_20240120_BCG.csv with 31_20240120_RR.csv\n",
      "\n",
      "Matched: 31_20240121_BCG.csv with 31_20240121_RR.csv\n",
      "\n",
      "Warning: BCG folder missing for subject 32\n",
      "\n",
      "Successfully loaded 2 BCG files with reference RR data\n",
      "\n",
      "Successfully loaded the following BCG files with references:\n",
      "1. 31_20240120_BCG.csv\n",
      "   Reference: 31_20240120_RR.csv\n",
      "2. 31_20240121_BCG.csv\n",
      "   Reference: 31_20240121_RR.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafez\\AppData\\Local\\Temp\\ipykernel_40028\\4205795995.py:67: UserWarning: Parsing dates in %Y/%m/%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Datetime'] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "all_bcg_data_with_ref = load_all_bcg_files_with_reference(dataset_folder)\n",
    "\n",
    "# Print summary\n",
    "if all_bcg_data_with_ref:\n",
    "    print(\"\\nSuccessfully loaded the following BCG files with references:\")\n",
    "    for i, (bcg_path, data) in enumerate(all_bcg_data_with_ref.items()):\n",
    "        print(f\"{i+1}. {os.path.basename(bcg_path)}\")\n",
    "        print(f\"   Reference: {os.path.basename(data['ref_file_path'])}\")\n",
    "else:\n",
    "    print(\"\\nNo matching BCG and reference files found. Please check:\")\n",
    "    print(\"1. The folder structure is correct\")\n",
    "    print(\"2. Files follow the naming convention: [name]_BCG.csv and [name]_RR.csv\")\n",
    "    print(\"3. Both files exist in their respective folders\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d990ec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: 31_20240120_BCG.csv\n",
      "First 3 BCG timestamps:\n",
      " 0   2024-01-19 16:53:36.989000000\n",
      "1   2024-01-19 16:53:36.996142822\n",
      "2   2024-01-19 16:53:37.003285645\n",
      "3   2024-01-19 16:53:37.010428467\n",
      "4   2024-01-19 16:53:37.017571533\n",
      "Name: Datetime, dtype: datetime64[ns]\n",
      "First 3 RR timestamps:\n",
      " 0   2024-01-20 00:52:12\n",
      "1   2024-01-20 00:52:12\n",
      "2   2024-01-20 00:52:12\n",
      "3   2024-01-20 00:52:13\n",
      "4   2024-01-20 00:52:13\n",
      "Name: Datetime, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Debug print to inspect datetime parsing\n",
    "for bcg_path, data in all_bcg_data_with_ref.items():\n",
    "    print(f\"\\nFile: {os.path.basename(bcg_path)}\")\n",
    "    print(\"First 3 BCG timestamps:\\n\", data['bcg_data']['Datetime'].head())\n",
    "    print(\"First 3 RR timestamps:\\n\", data['rr_data']['Datetime'].head())\n",
    "    break  # Remove 'break' if you want to print all files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a18002",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b30bd050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCG Data Columns: Index(['BCG', 'Timestamp', 'fs', 'Datetime'], dtype='object')\n",
      "RR Data Columns: Index(['Timestamp', 'HR', 'RR_Interval', 'Datetime'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafez\\AppData\\Local\\Temp\\ipykernel_40028\\4208086156.py:24: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def plot_bcg_signal(data_dict, title=\"BCG Signal\", samples_to_plot=1000):\n",
    "    \"\"\"Plot a segment of BCG data with proper timestamps\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Extract the DataFrame from the dictionary\n",
    "    df = data_dict['bcg_data']\n",
    "\n",
    "    # Plot first n samples\n",
    "    plot_df = df.head(samples_to_plot)\n",
    "\n",
    "    plt.plot(plot_df['Datetime'], plot_df['BCG'],\n",
    "             linewidth=1, alpha=0.8)\n",
    "\n",
    "    # Format x-axis\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(DateFormatter('%H:%M:%S.%f'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.title(f\"{title} (First {samples_to_plot} samples)\")\n",
    "    plt.ylabel(\"BCG Amplitude\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "# Plot first file as example\n",
    "if all_bcg_data_with_ref:\n",
    "    first_file_data = next(iter(all_bcg_data_with_ref.values()))\n",
    "    print(\"BCG Data Columns:\", first_file_data['bcg_data'].columns)\n",
    "    # Now available\n",
    "    print(\"RR Data Columns:\", first_file_data['rr_data'].columns)\n",
    "    plot_bcg_signal(first_file_data, title=\"BCG Signal Example\",\n",
    "                    samples_to_plot=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6b8b2",
   "metadata": {},
   "source": [
    "## 4. Synchronize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd075f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_alignment(bcg_data, rr_data):\n",
    "    \"\"\"Verify if BCG and RR data overlap in time\"\"\"\n",
    "    bcg_start = bcg_data['Datetime'].min()\n",
    "    bcg_end = bcg_data['Datetime'].max()\n",
    "    rr_start = rr_data['Datetime'].min()\n",
    "    rr_end = rr_data['Datetime'].max()\n",
    "    \n",
    "    print(f\"BCG Range: {bcg_start} to {bcg_end}\")\n",
    "    print(f\"RR Range:  {rr_start} to {rr_end}\")\n",
    "    \n",
    "    if rr_start > bcg_end or rr_end < bcg_start:\n",
    "        print(\"Warning: No temporal overlap between BCG and RR data!\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859fe267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronize_data(bcg_data, rr_data):\n",
    "    \"\"\"Align BCG and RR data based on timestamps\"\"\"\n",
    "    # Convert to pandas DateTimeIndex for both datasets\n",
    "    bcg_times = pd.DatetimeIndex(bcg_data['Datetime'])\n",
    "    rr_times = pd.DatetimeIndex(rr_data['Datetime'])\n",
    "    \n",
    "    # Find overlapping period\n",
    "    start_time = max(bcg_times.min(), rr_times.min())\n",
    "    end_time = min(bcg_times.max(), rr_times.max())\n",
    "    \n",
    "    # Filter both datasets to overlapping period\n",
    "    bcg_sync = bcg_data[bcg_data['Datetime'].between(start_time, end_time)]\n",
    "    rr_sync = rr_data[rr_data['Datetime'].between(start_time, end_time)]\n",
    "    \n",
    "    print(\"Synchronizing...\")\n",
    "    print(f\"BCG time range: {bcg_times.min()} to {bcg_times.max()}\")\n",
    "    print(f\"RR time range: {rr_times.min()} to {rr_times.max()}\")\n",
    "    print(f\"Overlapping window: {start_time} to {end_time}\")\n",
    "   \n",
    "    return {\n",
    "        'bcg': bcg_sync,\n",
    "        'rr': rr_sync,\n",
    "        'start_time': start_time,\n",
    "        'end_time': end_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa54a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Processing file: 31_20240120_BCG.csv\n",
      "   BCG start: 2024-01-19 16:53:36.989000, end: 2024-01-20 02:42:20.646142822\n",
      "   RR  start: 2024-01-20 00:52:12, end: 2024-01-20 10:40:28\n",
      "BCG Range: 2024-01-19 16:53:36.989000 to 2024-01-20 02:42:20.646142822\n",
      "RR Range:  2024-01-20 00:52:12 to 2024-01-20 10:40:28\n",
      "Synchronizing...\n",
      "BCG time range: 2024-01-19 16:53:36.989000 to 2024-01-20 02:42:20.646142822\n",
      "RR time range: 2024-01-20 00:52:12 to 2024-01-20 10:40:28\n",
      "Overlapping window: 2024-01-20 00:52:12 to 2024-01-20 02:42:20.646142822\n",
      "   ✅ Synchronized:\n",
      "      New BCG range: 2024-01-20 00:52:12.003285645 to 2024-01-20 02:42:20.646142822\n",
      "      New RR  range: 2024-01-20 00:52:12 to 2024-01-20 02:42:20\n",
      "\n",
      "📁 Processing file: 31_20240121_BCG.csv\n",
      "   BCG start: 2024-01-20 16:42:44.837000, end: 2024-01-21 01:19:59.979857178\n",
      "   RR  start: 2024-01-21 00:42:04, end: 2024-01-21 09:18:45\n",
      "BCG Range: 2024-01-20 16:42:44.837000 to 2024-01-21 01:19:59.979857178\n",
      "RR Range:  2024-01-21 00:42:04 to 2024-01-21 09:18:45\n",
      "Synchronizing...\n",
      "BCG time range: 2024-01-20 16:42:44.837000 to 2024-01-21 01:19:59.979857178\n",
      "RR time range: 2024-01-21 00:42:04 to 2024-01-21 09:18:45\n",
      "Overlapping window: 2024-01-21 00:42:04 to 2024-01-21 01:19:59.979857178\n",
      "   ✅ Synchronized:\n",
      "      New BCG range: 2024-01-21 00:42:04.001285645 to 2024-01-21 01:19:59.979857178\n",
      "      New RR  range: 2024-01-21 00:42:04 to 2024-01-21 01:19:59\n"
     ]
    }
   ],
   "source": [
    "# After loading data, for each subject:\n",
    "for bcg_path, data in all_bcg_data_with_ref.items():\n",
    "    bcg_df = data['bcg_data']\n",
    "    rr_df = data['rr_data']\n",
    "\n",
    "    print(f\"\\n📁 Processing file: {os.path.basename(bcg_path)}\")\n",
    "    print(f\"   BCG start: {bcg_df['Datetime'].min()}, end: {bcg_df['Datetime'].max()}\")\n",
    "    print(f\"   RR  start: {rr_df['Datetime'].min()}, end: {rr_df['Datetime'].max()}\")\n",
    "\n",
    "    # Check alignment first\n",
    "    if not check_time_alignment(bcg_df, rr_df):\n",
    "        print(\"   ❌ Skipped: No overlapping time range.\")\n",
    "        continue\n",
    "\n",
    "    # Synchronize data\n",
    "    synchronized = synchronize_data(bcg_df, rr_df)\n",
    "    \n",
    "    bcg_sync = synchronized['bcg']\n",
    "    rr_sync = synchronized['rr']\n",
    "\n",
    "    # Check if trimmed data is non-empty\n",
    "    if bcg_sync.empty or rr_sync.empty:\n",
    "        print(\"   ⚠️ Skipped: Synchronization resulted in empty data.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"   ✅ Synchronized:\")\n",
    "    print(f\"      New BCG range: {bcg_sync['Datetime'].min()} to {bcg_sync['Datetime'].max()}\")\n",
    "    print(f\"      New RR  range: {rr_sync['Datetime'].min()} to {rr_sync['Datetime'].max()}\")\n",
    "\n",
    "    # Update the dictionary with synchronized data\n",
    "    all_bcg_data_with_ref[bcg_path]['sync_data'] = synchronized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "273a8fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Using synchronized BCG from: 31_20240121_BCG.csv\n",
      "\n",
      "🟢 First 10 resampled BCG samples (50 Hz):\n",
      "                 Datetime          BCG     Timestamp  fs\n",
      "0 2024-01-21 00:42:04.000  -873.333333  1.705798e+12 NaN\n",
      "1 2024-01-21 00:42:04.020  -611.666667  1.705798e+12 NaN\n",
      "2 2024-01-21 00:42:04.040 -1767.000000  1.705798e+12 NaN\n",
      "3 2024-01-21 00:42:04.060    -9.666667  1.705798e+12 NaN\n",
      "4 2024-01-21 00:42:04.080   -20.000000  1.705798e+12 NaN\n",
      "5 2024-01-21 00:42:04.100   -67.666667  1.705798e+12 NaN\n",
      "6 2024-01-21 00:42:04.120 -1984.000000  1.705798e+12 NaN\n",
      "7 2024-01-21 00:42:04.140 -1514.000000  1.705798e+12 NaN\n",
      "8 2024-01-21 00:42:04.160  -874.666667  1.705798e+12 NaN\n",
      "9 2024-01-21 00:42:04.180 -1282.000000  1.705798e+12 NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_synchronized_data(all_data, filename_or_path):\n",
    "    \"\"\"\n",
    "    Returns synchronized BCG and RR data for a given file if available.\n",
    "\n",
    "    Parameters:\n",
    "        all_data (dict): Main data dictionary with paths and sync info.\n",
    "        filename_or_path (str): Filename or full path to identify the sample.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sync_bcg_df, sync_rr_df) or (None, None) if not found.\n",
    "    \"\"\"\n",
    "    for path, data in all_data.items():\n",
    "        if filename_or_path in path:\n",
    "            if 'sync_data' in data:\n",
    "                return data['sync_data']['bcg'].copy(), data['sync_data']['rr'].copy()\n",
    "            else:\n",
    "                print(f\"⚠️ No synchronized data found for: {os.path.basename(path)}\")\n",
    "                return None, None\n",
    "    print(f\"❌ File not found in dataset: {filename_or_path}\")\n",
    "    return None, None\n",
    "\n",
    "# 🔹 Choose the desired filename or path substring\n",
    "selected_file = \"31_20240121_BCG.csv\"  # <-- Change this to the subject/sample you want\n",
    "\n",
    "# 🔹 Retrieve synchronized data\n",
    "sync_bcg, sync_rr = get_synchronized_data(all_bcg_data_with_ref, selected_file)\n",
    "\n",
    "# 🔹 Process BCG if available\n",
    "if sync_bcg is not None:\n",
    "    print(f\"\\n📁 Using synchronized BCG from: {selected_file}\")\n",
    "\n",
    "    # Set datetime as index\n",
    "    sync_bcg.set_index('Datetime', inplace=True)\n",
    "\n",
    "    # Resample to 50 Hz (20 ms intervals)\n",
    "    bcg_resampled = sync_bcg.resample('20ms').mean().interpolate(method='linear')\n",
    "\n",
    "    # Reset index\n",
    "    bcg_resampled.reset_index(inplace=True)\n",
    "\n",
    "    # Display first 10 samples\n",
    "    print(\"\\n🟢 First 10 resampled BCG samples (50 Hz):\")\n",
    "    print(bcg_resampled.head(10))\n",
    "else:\n",
    "    print(\"⚠️ Unable to resample: No synchronized BCG data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b1bc21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>BCG</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>fs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-21 00:42:04.000</td>\n",
       "      <td>-873.333333</td>\n",
       "      <td>1.705798e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-21 00:42:04.020</td>\n",
       "      <td>-611.666667</td>\n",
       "      <td>1.705798e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-21 00:42:04.040</td>\n",
       "      <td>-1767.000000</td>\n",
       "      <td>1.705798e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-21 00:42:04.060</td>\n",
       "      <td>-9.666667</td>\n",
       "      <td>1.705798e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-21 00:42:04.080</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>1.705798e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113794</th>\n",
       "      <td>2024-01-21 01:19:59.880</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>1.705800e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113795</th>\n",
       "      <td>2024-01-21 01:19:59.900</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.705800e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113796</th>\n",
       "      <td>2024-01-21 01:19:59.920</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.705800e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113797</th>\n",
       "      <td>2024-01-21 01:19:59.940</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>1.705800e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113798</th>\n",
       "      <td>2024-01-21 01:19:59.960</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>1.705800e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113799 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime          BCG     Timestamp  fs\n",
       "0      2024-01-21 00:42:04.000  -873.333333  1.705798e+12 NaN\n",
       "1      2024-01-21 00:42:04.020  -611.666667  1.705798e+12 NaN\n",
       "2      2024-01-21 00:42:04.040 -1767.000000  1.705798e+12 NaN\n",
       "3      2024-01-21 00:42:04.060    -9.666667  1.705798e+12 NaN\n",
       "4      2024-01-21 00:42:04.080   -20.000000  1.705798e+12 NaN\n",
       "...                        ...          ...           ...  ..\n",
       "113794 2024-01-21 01:19:59.880    90.500000  1.705800e+12 NaN\n",
       "113795 2024-01-21 01:19:59.900    77.000000  1.705800e+12 NaN\n",
       "113796 2024-01-21 01:19:59.920    65.000000  1.705800e+12 NaN\n",
       "113797 2024-01-21 01:19:59.940    61.333333  1.705800e+12 NaN\n",
       "113798 2024-01-21 01:19:59.960    58.333333  1.705800e+12 NaN\n",
       "\n",
       "[113799 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcg_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e72f5e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Datetime          BCG      Timestamp  fs\n",
      "0 2024-01-21 00:42:04.000  -873.333333  1705797724000  50\n",
      "1 2024-01-21 00:42:04.020  -611.666667  1705797724020  50\n",
      "2 2024-01-21 00:42:04.040 -1767.000000  1705797724040  50\n",
      "3 2024-01-21 00:42:04.060    -9.666667  1705797724060  50\n",
      "4 2024-01-21 00:42:04.080   -20.000000  1705797724080  50\n",
      "5 2024-01-21 00:42:04.100   -67.666667  1705797724100  50\n",
      "6 2024-01-21 00:42:04.120 -1984.000000  1705797724120  50\n",
      "7 2024-01-21 00:42:04.140 -1514.000000  1705797724140  50\n",
      "8 2024-01-21 00:42:04.160  -874.666667  1705797724160  50\n",
      "9 2024-01-21 00:42:04.180 -1282.000000  1705797724180  50\n"
     ]
    }
   ],
   "source": [
    "# Regenerate Timestamp (in milliseconds)\n",
    "bcg_resampled['Timestamp'] = bcg_resampled['Datetime'].astype('int64') // 10**6\n",
    "\n",
    "# Set the new sampling frequency\n",
    "bcg_resampled['fs'] = 50\n",
    "\n",
    "# Preview again\n",
    "print(bcg_resampled.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d9a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved resampled BCG to resampled_bcg_31_20240121.csv\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Save resampled BCG to CSV\n",
    "resampled_path = \"resampled_bcg_31_20240121.csv\"\n",
    "bcg_resampled['Timestamp'] = bcg_resampled['Datetime'].astype('int64') // 10**6  # Convert to ms\n",
    "bcg_resampled['fs'] = 50  # Sampling frequency\n",
    "bcg_resampled[['Timestamp', 'BCG']].to_csv(resampled_path, index=False)\n",
    "print(f\"✅ Saved resampled BCG to {resampled_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8b5305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load resampled data for analysis\n",
    "df = pd.read_csv(resampled_path)\n",
    "rawData = df[['Timestamp', 'BCG']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0a2e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs\n",
    "utc_time = bcg_resampled['Timestamp']  # milliseconds\n",
    "utc_time = utc_time.to_numpy()\n",
    "data_stream = bcg_resampled['BCG']\n",
    "fs = 50\n",
    "start_point, end_point, window_shift = 0, 500, 500\n",
    "\n",
    "results_dir = r\"D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# ==========================================================================================================\n",
    "# Pattern detection (e.g. motion artifact removal)\n",
    "data_stream, utc_time = detect_patterns(start_point, end_point, window_shift, data_stream, utc_time, plot=1)\n",
    "\n",
    "# ==========================================================================================================\n",
    "# BCG signal extraction\n",
    "movement = band_pass_filtering(data_stream, fs, \"bcg\")\n",
    "\n",
    "# ==========================================================================================================\n",
    "# Respiratory signal extraction\n",
    "breathing = band_pass_filtering(data_stream, fs, \"breath\")\n",
    "breathing = remove_nonLinear_trend(breathing, 3)\n",
    "breathing = savgol_filter(breathing, 11, 3)\n",
    "\n",
    "# ==========================================================================================================\n",
    "# Wavelet decomposition for cardiac cycle extraction\n",
    "w = modwt(movement, 'bior3.9', 4)\n",
    "dc = modwtmra(w, 'bior3.9')\n",
    "wavelet_cycle = dc[4]\n",
    "\n",
    "# ==========================================================================================================\n",
    "# Vital signs estimation (e.g., Heart Rate)\n",
    "t1, t2, window_length, window_shift = 0, 500, 500, 500\n",
    "hop_size = math.floor((window_length - 1) / 2)\n",
    "limit = int(math.floor(breathing.size / window_shift))\n",
    "\n",
    "# Heart Rate estimation from wavelet_cycle\n",
    "beats = vitals(t1, t2, window_shift, limit, wavelet_cycle, utc_time, mpd=1, plot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7287e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafez\\AppData\\Local\\Temp\\ipykernel_40028\\1238226132.py:17: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  hr_df_avg_10s = numeric_cols.resample('10S').mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# If datetime is not in columns but is already the index, reset and convert\n",
    "if 'Timestamp' not in sync_rr.columns:\n",
    "    sync_rr = sync_rr.reset_index()\n",
    "\n",
    "# Now ensure it's in datetime format\n",
    "sync_rr['Timestamp'] = pd.to_datetime(sync_rr['Timestamp'])\n",
    "\n",
    "# Set datetime as index\n",
    "sync_rr = sync_rr.set_index('Timestamp')\n",
    "\n",
    "# Keep only numeric columns (like Heart Rate and RR Interval)\n",
    "numeric_cols = sync_rr.select_dtypes(include='number')\n",
    "\n",
    "# Resample every 10 seconds and compute mean\n",
    "hr_df_avg_10s = numeric_cols.resample('10S').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b90f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Timestamp         HR  RR_Interval\n",
      "0   2024-01-21 00:42:00  84.444444     0.718000\n",
      "1   2024-01-21 00:42:10  84.538462     0.705692\n",
      "2   2024-01-21 00:42:20  84.000000     0.723714\n",
      "3   2024-01-21 00:42:30  83.307692     0.738385\n",
      "4   2024-01-21 00:42:40  81.933333     0.722333\n",
      "..                  ...        ...          ...\n",
      "223 2024-01-21 01:19:10  66.750000     0.899000\n",
      "224 2024-01-21 01:19:20  67.909091     0.871091\n",
      "225 2024-01-21 01:19:30  66.200000     0.959900\n",
      "226 2024-01-21 01:19:40  65.166667     0.916250\n",
      "227 2024-01-21 01:19:50  67.363636     0.858909\n",
      "\n",
      "[228 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hr_df_avg_10s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef2ab466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c1cbbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the raw reference file:\n",
      "           Timestamp  Heart Rate  RR Interval in seconds\n",
      "0  2024/1/21 0:42:04          86                   0.719\n",
      "1  2024/1/21 0:42:05          85                   0.753\n",
      "2  2024/1/21 0:42:05          85                   0.765\n",
      "3  2024/1/21 0:42:07          84                   0.741\n",
      "4  2024/1/21 0:42:07          84                   0.692\n",
      "\n",
      "Timestamp dtype before conversion:\n",
      "object\n",
      "\n",
      "Max timestamp value: 2024/1/21 9:18:45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reference_df = pd.read_csv(\n",
    "    r\"D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\data\\dataset\\data\\31\\Reference\\RR\\31_20240121_RR.csv\"\n",
    ")\n",
    "\n",
    "print(\"First few rows of the raw reference file:\")\n",
    "print(reference_df.head())\n",
    "\n",
    "print(\"\\nTimestamp dtype before conversion:\")\n",
    "print(reference_df['Timestamp'].dtype)\n",
    "\n",
    "print(\"\\nMax timestamp value:\", reference_df['Timestamp'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6de1f943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure both arrays have the same length\n",
    "min_length = min(len(beats), len(hr_df_avg_10s))\n",
    "\n",
    "# Trim the larger one\n",
    "beats_trimmed = beats[:min_length]\n",
    "hr_df_avg_10s_trimmed = hr_df_avg_10s[:min_length]\n",
    "\n",
    "len(hr_df_avg_10s_trimmed)\n",
    "#len(beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac8bdcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>HR</th>\n",
       "      <th>RR_Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-21 00:42:00</td>\n",
       "      <td>84.444444</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-21 00:42:10</td>\n",
       "      <td>84.538462</td>\n",
       "      <td>0.705692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-21 00:42:20</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.723714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-21 00:42:30</td>\n",
       "      <td>83.307692</td>\n",
       "      <td>0.738385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-21 00:42:40</td>\n",
       "      <td>81.933333</td>\n",
       "      <td>0.722333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2024-01-21 01:19:00</td>\n",
       "      <td>67.909091</td>\n",
       "      <td>0.892273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2024-01-21 01:19:10</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>0.899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2024-01-21 01:19:20</td>\n",
       "      <td>67.909091</td>\n",
       "      <td>0.871091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2024-01-21 01:19:30</td>\n",
       "      <td>66.200000</td>\n",
       "      <td>0.959900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2024-01-21 01:19:40</td>\n",
       "      <td>65.166667</td>\n",
       "      <td>0.916250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Timestamp         HR  RR_Interval\n",
       "0   2024-01-21 00:42:00  84.444444     0.718000\n",
       "1   2024-01-21 00:42:10  84.538462     0.705692\n",
       "2   2024-01-21 00:42:20  84.000000     0.723714\n",
       "3   2024-01-21 00:42:30  83.307692     0.738385\n",
       "4   2024-01-21 00:42:40  81.933333     0.722333\n",
       "..                  ...        ...          ...\n",
       "222 2024-01-21 01:19:00  67.909091     0.892273\n",
       "223 2024-01-21 01:19:10  66.750000     0.899000\n",
       "224 2024-01-21 01:19:20  67.909091     0.871091\n",
       "225 2024-01-21 01:19:30  66.200000     0.959900\n",
       "226 2024-01-21 01:19:40  65.166667     0.916250\n",
       "\n",
       "[227 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_df_avg_10s_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe4d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR=hr_df_avg_10s_trimmed['HR'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33d8f68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.704224492608816\n",
      "Root Mean Square Error (RMSE): 10.798206442880389\n",
      "Mean Absolute Percentage Error (MAPE): 12.28%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Ensure both are NumPy arrays\n",
    "beats_trimmed = np.array(beats_trimmed)\n",
    "HR = np.array(HR)\n",
    "\n",
    "# Ensure they are of the same length\n",
    "min_length = min(len(beats_trimmed), len(HR))\n",
    "beats_trimmed = beats_trimmed[:min_length]\n",
    "HR = HR[:min_length]\n",
    "\n",
    "# Drop NaN values and exclude zeros in HR\n",
    "valid_indices = ~np.isnan(beats_trimmed) & ~np.isnan(HR) & (HR != 0)\n",
    "beats_trimmed = beats_trimmed[valid_indices]\n",
    "HR = HR[valid_indices]\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(HR, beats_trimmed)\n",
    "rmse = np.sqrt(mean_squared_error(HR, beats_trimmed))\n",
    "mape = np.mean(np.abs((HR - beats_trimmed) / HR)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Root Mean Square Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "983510c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Bland-Altman plot to D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\results\\bland_altman_plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafez\\AppData\\Local\\Temp\\ipykernel_40028\\1850870105.py:21: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "mean_hr = (HR + beats_trimmed) / 2\n",
    "diff_hr = HR - beats_trimmed\n",
    "mean_diff = np.mean(diff_hr)\n",
    "std_diff = np.std(diff_hr)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(mean_hr, diff_hr, alpha=0.5)\n",
    "plt.axhline(mean_diff, color='gray', linestyle='--', label=f'Mean diff = {mean_diff:.2f}')\n",
    "plt.axhline(mean_diff + 1.96*std_diff, color='red', linestyle='--', label='±1.96 SD')\n",
    "plt.axhline(mean_diff - 1.96*std_diff, color='red', linestyle='--')\n",
    "plt.title('Bland-Altman Plot')\n",
    "plt.xlabel('Mean of Estimated and Reference HR')\n",
    "plt.ylabel('Difference (Estimated - Reference)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(r\"D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\results\\bland_altman_plot.png\")\n",
    "plt.show()\n",
    "print(f\"Saved Bland-Altman plot to {os.path.join(results_dir, 'bland_altman_plot.png')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5649ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Pearson correlation plot to D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\results\\pearson_correlation_plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafez\\AppData\\Local\\Temp\\ipykernel_40028\\1210112934.py:13: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr_coef, _ = pearsonr(beats_trimmed, HR)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.regplot(x=beats_trimmed, y=HR, ci=None, scatter_kws={\"alpha\":0.5})\n",
    "plt.title(f'Pearson Correlation (r = {corr_coef:.2f})')\n",
    "plt.xlabel('Reference HR')\n",
    "plt.ylabel('Estimated HR')\n",
    "plt.grid(True)\n",
    "plt.savefig(r\"D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\results\\pearson_correlation_plot.png\")\n",
    "plt.show()\n",
    "print(f\"Saved Pearson correlation plot to {os.path.join(results_dir, 'pearson_correlation_plot.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50115ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved boxplot to D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\results\\hr_boxplot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafez\\AppData\\Local\\Temp\\ipykernel_40028\\1150286172.py:13: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'HR': np.concatenate([beats_trimmed, HR]),\n",
    "    'Type': ['Reference'] * len(beats_trimmed) + ['Estimated'] * len(HR)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.boxplot(x='Type', y='HR', data=df)\n",
    "plt.title('Boxplot of Reference and Estimated HR')\n",
    "plt.grid(True)\n",
    "plt.savefig(r\"D:\\Ahmed Hafez\\Ahmed Hafez\\College\\Data Analytics\\Project\\final project\\results\\hr_boxplot.png\")\n",
    "plt.show()\n",
    "print(f\"Saved boxplot to {os.path.join(results_dir, 'hr_boxplot.png')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
